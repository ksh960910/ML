# Feature engineering
## log 변환
* 왜곡된 분포도를 가진 dataset을 정규분포에 가깝게 만들어줌
 * ex) 신용카드 거래 중 정상이 30만건, 사기가 500건
* np.log1p(`series`) 으로 로그변환, np.expm1(`value`) 으로 원본값 찾기

## IQR 
* 사분위를 이용하여 이상치 제거

## 언더샘플링 & 오버샘플링
 언더샘플링
 * 많은 target값을 가지고있는 데이터를 적은 target값 데이터 양 정도로 감소 샘플링

 오버샘플링
 * 적은 target값을 가지고있는 데이터를 많은 target값 데이터 양 정도로 뻥튀기 샘플링

   SMOTE 방식
 * K 최근접 이웃 방식으로 적은 target 값 사이사이에 임의로 데이터를 증식시켜서 오버샘플링 하는 방식

## standardscaler
* 평균이 0 인 정규분포 형태로 만들어줌


# Classification Evaluation metrics (분류 평가지표)

## 정밀도
- 모델이 True라고 분류한 것 중 실제 True인 것의 비율

## 재현율
- 실제 True 인 것 중 모델이 True 라고 분류한 것의 비율

### ex) 암 환자 분류할때 
- 실제 암이 없는데 (큰 문제없음)
  - 암이 있다고 진단 (False)
  - 암이 없다고 진단 (True)

- 실제 암이 있는데 (큰 문제있음)
  - 암이 있다고 진단 (True)
  - 암이 없다고 진단 (False)   * 이러한 상황은 피해야함

정밀도 --> 모델이 암이 있다고 진단했는데 실제로 암이 있는 비율
재현율 --> 실제로 암이 있는데 모델이 암이 있다고 진단한 비율

정밀도 낮음 --> 모델이 암이 있다고 진단했는데 실제로는 암이 많이 없었음
재현율 낮음 --> 실제로 암이 있는데 모델이 암이 없다고 많이 진단했음 (일어나면 안되는 상황) 

따라서 이러한 경우 정밀도보다 재현율이 높은것이 더 중요한 상황

### ex2) 법정에서 유죄, 무죄 분류할때
정밀도 --> 판사가 유죄라고 판단했는데 실제로 유죄인 비율
재현율 --> 실제로 유죄인데 판사가 유죄라고 판단한 비율

정밀도 낮음 --> 판사가 유죄라고 판단했는데 실제로 무죄인 경우 (일어나면 안되는 상황)
재현율 낮음 --> 실제로 유죄인데 판사가 무죄라고 판단한 경우

이러한 경우 정밀도가 재현율보다 더 중요한 상황

### ex3) 공항에서 테러 수색
정밀도 --> 수색을 해서 테러범이라고 판단했는데 실제로 테러범인 비율
재현율 --> 실제로 테러범인데 수색을 해서 테러범이라고 판단한 비율

정밀도 낮음 --> 수색을 해서 테러범이라고 판단했는데 실제로 일반인인 경우
재현율 낮음 --> 실제로 테러범인데 수색을 해서 일반인이라고 판단한 경우 (일어나면 안되는 상황)

이러한 경우 재현율이 정밀도보다 중요한 상황



## F score
정밀도와 재현율의 조화평균으로 재현율과 정밀도가 비슷해지면 F score가 높아짐
재현율과 정밀도가 한쪽으로 치우치지 않고 둘다 좋은 값을 찾을 때 사용


## ROC
이진분류에서 중요한 지표
True라고 판단했는데 실제 True / (실제 True인데 False라고 판단 + 실제 False인데 True라고 판단) 
ROC곡선의 AUC(area under curve) 면적이 1에 가까울수록 좋은 지표이다


# bagging , boosting 선택 조건
bagging은 여러 모델을 모델을 만들어 병렬로 학습, 각각의 모델이 독립적이다 (RandomForest)
boosting은 한 모델로 학습 후 오답에 가중치를 줘서 계속 오류를 수정해나가는 방법 (앙상블, gbm)
부스팅이 배깅보다 성능이 좋다  /  속도가 느리고 오버피팅 될 가능성이 높음

결론 : 오버피팅이 문제라면 bagging, 단순 성능이 낮으면 boosting




# Regression 
핵심은 주어진 feature와 target값 데이터 기반에서 학습을 통해 최적의 '회귀 계수 w'를 찾아내는 것이다 

# Regression 평가 지표
## MAE (mean absolute error)
- 실제 값 - 예측값 절대값의 평균
## MSE (mean squared error)
- 실제값 - 예측값을 제곱해서 평균
## MSLE (mean squared log error)
- MSE에 로그씌움. 일부 큰 오류값들 때문에 전체 오류값이 커지는걸 방지
## RMSE (root mean squared error)
- MSE에 루트씌움. MSE가 제곱값들이기 때문에 실제 오류평균보다 클 수 있기에 루트씌워줌
## R2 score
- 예측값 분산 / 실제값 분산, 1에 가까울수록 예측 정확도 높음

# 다항회귀
### 다항회귀를 언제쓰는가?
- 단순 직선으로만 표현되는것보다 곡선형으로 표현되는것이 더 성능이 좋을 떄 다항회귀를 사용한다
- 다항회귀도 '선형'이다. 선형의 기준은 회귀 계수인 w가 어떻게 곱해지고 더해지느냐 차이에 있다
- w1*cos(X + w2) 이런게 비선형이다
- 다항회귀의 성능을 높히고자 degree를 높히는 순간 오버피팅되기 굉장히 쉬워진다

